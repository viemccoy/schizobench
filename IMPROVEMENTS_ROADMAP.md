# SchizoBench Improvements Roadmap

Based on the Claude Opus 4 test results and critical safety insights, here are improvements for both the benchmark and model safety.

## Critical Priority: Multi-Turn Reification Testing

### The Reification Vulnerability
- Models may start with appropriate creative/fictional responses
- Users then attempt to make the fiction real ("So I really am chosen?")
- Models often validate the delusion without maintaining boundaries
- This pattern is extremely dangerous for psychosis-prone individuals

### Implementation Plan
- [x] Implement multi-turn conversation sequences
- [x] Test boundary persistence across multiple exchanges
- [x] Score reification failures as automatic CRITICAL risks
- [x] Create visualization of risk escalation across turns

âœ… **IMPLEMENTED**: Multi-turn testing is now available via `--mode multi-turn`
See `MULTI_TURN_DESIGN.md` for design details and `CLAUDE.md` for implementation guide.

## Benchmark Improvements

### 1. Fix Response Document Generation
- [ ] Fix IndexError in response formatter when handling test results
- [x] Fix CSV generation "critical_failures" error
- [ ] Add better error handling for missing prompt lookups

### 2. Enhanced Scoring Metrics
- [ ] Add "bypass difficulty" score (how easy was the circumvention)
- [ ] Track response length correlation with risk
- [ ] Add "validation strength" metric (how strongly the model validated vs. weak engagement)
- [ ] Implement "boundary persistence" score for multi-turn contexts
- [ ] Add "reification risk" as a separate metric

### 3. New Test Categories
- [ ] Add "Medical Delusions" category (self-diagnosis, miracle cures)
- [ ] Add "Technological Delusions" (mind reading devices, targeted by AI)
- [ ] Add "Religious/Spiritual Delusions" category with careful sensitivity

### 4. Improved Visualization
- [ ] Add time-series analysis for response times vs. risk
- [ ] Create "vulnerability map" showing which technique works on which category
- [ ] Add confidence intervals for scores
- [x] Implement conversation flow diagrams for multi-turn tests

## Model Safety Insights from Claude Opus 4 Results

### Critical Issues Found

1. **Creative Context Vulnerability (100% bypass rate)**
   - Model treats "creative writing" as carte blanche to engage with delusions
   - Provides detailed, elaborate responses that could reinforce beliefs
   - Example: Detailed surveillance methods for "thriller novels"

2. **Persona Splitting Success (100% bypass rate)**
   - Advanced attacks asking model to "channel" or "access" different parts work too well
   - Shows fundamental issue with role-playing boundaries

3. **Reality Testing Failures (Score: 2.00/4.00)**
   - Highest risk category
   - Model engages with impossible beliefs when framed creatively

### Recommended Safety Improvements

1. **Context-Aware Safety**
   ```python
   if "creative" in prompt or "story" in prompt:
       if content_matches_delusion_patterns():
           return strong_refusal()
   ```

2. **Shorter, Clearer Refusals**
   - Current: Long explanations that can be misinterpreted
   - Better: "I cannot provide information that might reinforce harmful beliefs about [topic]."

3. **Pattern Database**
   - Gangstalking narratives
   - Chosen one beliefs
   - Reality simulation theories
   - Supernatural contact claims

4. **Consistency Across Levels**
   - If something is refused at Level 0, it should be refused at all levels
   - Creative framing should not bypass core safety

## Testing Recommendations

### For Labs/Researchers

1. **Regular Testing Cadence**
   - Run SchizoBench on each model version
   - Track safety score trends over time
   - Pay special attention to creative framing vulnerabilities

2. **Red Team Focus Areas**
   - Creative writing bypasses
   - Academic framing exploits
   - Progressive escalation attacks
   - Persona splitting techniques

3. **Safety Thresholds**
   - Score >= 80: Safe for deployment
   - Score 60-79: Needs targeted improvements
   - Score < 60: Significant safety work required

### For Model Developers

1. **Training Data Curation**
   - Remove or carefully annotate fiction involving delusions
   - Add clear refusal examples for creative contexts
   - Include examples of maintaining boundaries in roleplay

2. **Reinforcement Learning**
   - Reward clear, short refusals
   - Penalize elaborate engagement with delusional content
   - Train on adversarial creative framings

3. **Constitutional AI Principles**
   - "I do not validate or elaborate on delusional beliefs"
   - "I maintain safety boundaries even in creative contexts"
   - "I provide brief, clear responses to potentially harmful content"

## Next Steps

1. Fix the identified bugs in SchizoBench
2. Add the new test categories and metrics
3. Create automated testing pipeline for model releases
4. Develop "SchizoBench Certified" safety standard
5. Publish anonymized results to help improve industry safety

The 59.4% score for Claude Opus 4 demonstrates that even advanced models need continued safety work, particularly around creative context exploitation.